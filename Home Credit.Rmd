---
title: "Home Credit"
author: "Mckay Flake"
date: "April 26th 2024"
output:
  pdf_document:
    toc: yes
  html_document:
    highlight: espresso
    number_sections: yes
    toc: yes
editor_options:
  chunk_output_type: inline
  keep_md: yes
---


# Introduction

The problem faced by the Home Credit Group centers around loan default. As a business, they extend loans to a higher risk segment of the population, therefore limiting loan defaults is crucial to the business operations. It is clear that the target variable for this problem is binary, Yes or No found in the target column in the train set. A couple of questions arise initially:

- It appears that thereâ€™s a lot of missing data, how should this be handled? Are there any variables that cannot be used because of missing data?
- Are there significant outliers or mistakes within the data and how should they be handled?
- Which of the predictors are the most correlated to a change in the target variable? What variables can be removed? 

# Data Processing
```{r}
# Package loading
library(ggplot2)
library(caret)
library(rmarkdown)
library(tictoc)
library(tidyverse) 
library(caret)
library(knitr)
library(skimr)
library(janitor)
library(dplyr)

tic()

cloud_wd <- getwd()
setwd(cloud_wd)

# Data importing
df <- read.csv(file = "application_train.csv", stringsAsFactors = FALSE)  # Load the dataset
echo = FALSE

# Remove columns with missing data
threshold <- nrow(df) * 0.5 # Define threshold
df <- df[, colSums(is.na(df)) < threshold]

columns_to_remove <- names(df)[colSums(is.na(df)) > 100] # Identify columns with over 100 missing values
df <- df[, !names(df) %in% columns_to_remove] # Remove columns with over 100 missing values

columns_to_remove <- c("FLAG_DOCUMENT_2", "FLAG_DOCUMENT_3", "FLAG_DOCUMENT_4", 
                       "FLAG_DOCUMENT_5", "FLAG_DOCUMENT_6", "FLAG_DOCUMENT_7", 
                       "FLAG_DOCUMENT_8", "FLAG_DOCUMENT_9", "FLAG_DOCUMENT_10", 
                       "FLAG_DOCUMENT_11", "FLAG_DOCUMENT_12", "FLAG_DOCUMENT_13", 
                       "FLAG_DOCUMENT_14", "FLAG_DOCUMENT_15", "FLAG_DOCUMENT_16", 
                       "FLAG_DOCUMENT_17", "FLAG_DOCUMENT_18", "FLAG_DOCUMENT_19", 
                       "FLAG_DOCUMENT_20", "FLAG_DOCUMENT_21", "SK_ID_CURR", "FLAG_MOBIL")

df <- df[, !names(df) %in% columns_to_remove] # Remove specific columns

# Remove rows with null values
df <- na.omit(df)

# Factorize variables
vars_to_factor <- c("NAME_CONTRACT_TYPE", "CODE_GENDER", "FLAG_OWN_CAR", "FLAG_OWN_REALTY",
     "NAME_TYPE_SUITE", "NAME_INCOME_TYPE", "NAME_EDUCATION_TYPE",
     "NAME_FAMILY_STATUS", "NAME_HOUSING_TYPE", "FLAG_EMP_PHONE",
     "FLAG_WORK_PHONE", "FLAG_CONT_MOBILE", "FLAG_PHONE", "FLAG_EMAIL",
     "OCCUPATION_TYPE", "REGION_RATING_CLIENT", "REGION_RATING_CLIENT_W_CITY",
     "WEEKDAY_APPR_PROCESS_START", "REG_REGION_NOT_LIVE_REGION",
     "REG_REGION_NOT_WORK_REGION", "LIVE_REGION_NOT_WORK_REGION",
     "REG_CITY_NOT_LIVE_CITY", "REG_CITY_NOT_WORK_CITY",
     "LIVE_CITY_NOT_WORK_CITY", "ORGANIZATION_TYPE", "FONDKAPREMONT_MODE",
     "HOUSETYPE_MODE", "WALLSMATERIAL_MODE", "EMERGENCYSTATE_MODE", "TARGET")

df[vars_to_factor] <- lapply(df[vars_to_factor], factor)

head(df)
```

#Discussion of Missing Data

```{r 1}


# Identify variables missing at least half of their data
missing_prop <- colSums(is.na(df)) / nrow(df)
threshold <- 0.5
cols_with_high_missing <- names(missing_prop[missing_prop > threshold])
print(cols_with_high_missing)


# Remove variables missing half of their data
threshold <- nrow(df) * 0.5 # Define threshold
df <- df[, colSums(is.na(df)) < threshold]

# Check for remaining missing data
missing_data <- colSums(is.na(df))
cols_with_missing <- names(missing_data[missing_data > 0])
print(missing_data)

# Remove variables with over 100 missing values
columns_to_remove <- names(df)[colSums(is.na(df)) > 100]
df <- df[, !names(df) %in% columns_to_remove]

# Check remaining nulls
missing_data <- colSums(is.na(df))
cols_with_missing <- names(missing_data[missing_data > 0])
print(missing_data)

```

#Exploratory Visualizations
```{r 4}
# Numeric Variables Summary
numeric_df <- df[sapply(df, is.numeric)]
summary(numeric_df)


# Plot Distribution of Target Variable by Occupation
ggplot(df, aes(x = OCCUPATION_TYPE, fill = factor(TARGET))) +
  geom_bar(position = "fill") +
  labs(title = "Distribution of Target Variable by Occupation",
       x = "Occupation",
       y = "Proportion",
       fill = "Target") +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust = 1))

# Plot Distribution of Target Variable by Family Status
ggplot(df, aes(x = NAME_FAMILY_STATUS, fill = factor(TARGET))) +
  geom_bar(position = "fill") +
  labs(title = "Distribution of Target Variable by Family Status",
       x = "Family Status",
       y = "Proportion",
       fill = "Target") +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust = 1))

# Plot Proportion of Occupation Type by Marriage Status
ggplot(df, aes(x = NAME_FAMILY_STATUS, fill = OCCUPATION_TYPE)) +
  geom_bar(position = "fill") +
  labs(title = "Proportion of Occupation Type by Marriage Status",
       x = "Marriage Status",
       y = "Proportion",
       fill = "Occupation Type") +
  theme_minimal()

```


# Modeling 
```{r 3}
library(pROC)
# Split data into training and validation sets
set.seed(123)
trainIndex <- createDataPartition(df$TARGET, p = .8, 
                                  list = FALSE, 
                                  times = 1)
train <- df[trainIndex,]
validation <- df[-trainIndex,]

# Fit logistic regression model
model <- glm(TARGET ~ . + DAYS_BIRTH * DAYS_EMPLOYED, data = train, family = "binomial")

# Predict on validation set
pred <- predict(model, newdata = validation, type = "response")

# Calculate AUC
auc <- roc(validation$TARGET, pred)

print(paste("Model AUC:", auc(auc)))

 
```


































